# Googleãƒˆãƒ¬ãƒ³ãƒ‰è‡ªå‹•ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° & ãƒ¡ãƒ¼ãƒ«é€ä¿¡
# æ¯æ—¥åˆå‰10æ™‚ï¼ˆJSTï¼‰= åˆå‰1æ™‚ï¼ˆUTCï¼‰ã«å®Ÿè¡Œ

name: Daily Google Trends Scraping

on:
  schedule:
    # æ¯æ—¥åˆå‰1æ™‚ï¼ˆUTCï¼‰= åˆå‰10æ™‚ï¼ˆJSTï¼‰ã«å®Ÿè¡Œ
    - cron: '0 1 * * *'

  # æ‰‹å‹•å®Ÿè¡Œã‚‚å¯èƒ½
  workflow_dispatch:
    inputs:
      keyword:
        description: 'ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰'
        required: false
        default: 'ãµã‚‹ã•ã¨ç´ç¨'

jobs:
  scrape-trends:
    runs-on: ubuntu-latest

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Scrape Google Trends and Send Email
        env:
          APP_URL: ${{ secrets.APP_URL }}
          CRON_SECRET: ${{ secrets.CRON_SECRET }}
          KEYWORD: ${{ github.event.inputs.keyword || 'ãµã‚‹ã•ã¨ç´ç¨' }}
        run: |
          echo "ğŸ” Scraping Google Trends for keyword: $KEYWORD"

          # APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’æ§‹ç¯‰
          URL="${APP_URL}/api/trends/scrape?secret=${CRON_SECRET}&keyword=${KEYWORD}"

          # APIã‚’å‘¼ã³å‡ºã—
          RESPONSE=$(curl -s -w "\n%{http_code}" -X GET "$URL")
          HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
          BODY=$(echo "$RESPONSE" | sed '$d')

          echo "ğŸ“¡ HTTP Status: $HTTP_CODE"
          echo "ğŸ“„ Response Body:"
          echo "$BODY" | jq '.' || echo "$BODY"

          # HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
          if [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 300 ]; then
            echo "âœ… Successfully scraped Google Trends"
          else
            echo "âŒ Failed to scrape Google Trends"
            exit 1
          fi

      - name: Notify on failure
        if: failure()
        run: |
          echo "âŒ Trends scraping job failed!"
          echo "Check the logs for more details."
