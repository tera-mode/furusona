# Google„Éà„É¨„É≥„ÉâËá™Âãï„Çπ„ÇØ„É¨„Ç§„Éî„É≥„Ç∞ & „É°„Éº„É´ÈÄÅ‰ø°
# Êúà„ÉªÊú®„ÉªÊó•„ÅÆÂçàÂâç10ÊôÇÔºàJSTÔºâ= ÂçàÂâç1ÊôÇÔºàUTCÔºâ„Å´ÂÆüË°å

name: Google Trends Scraping

on:
  schedule:
    # ÊúàÊõú„ÉªÊú®Êõú„ÉªÊó•Êõú„ÅÆÂçàÂâç1ÊôÇÔºàUTCÔºâ= ÂçàÂâç10ÊôÇÔºàJSTÔºâ„Å´ÂÆüË°å
    - cron: '0 1 * * 0,1,4'

  # ÊâãÂãïÂÆüË°å„ÇÇÂèØËÉΩ
  workflow_dispatch:
    inputs:
      keyword:
        description: '„Çπ„ÇØ„É¨„Ç§„Éî„É≥„Ç∞ÂØæË±°„Ç≠„Éº„ÉØ„Éº„Éâ'
        required: false
        default: '„Åµ„Çã„Åï„Å®Á¥çÁ®é'

jobs:
  scrape-trends:
    runs-on: ubuntu-latest

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Scrape Google Trends and Send Email
        env:
          APP_URL: ${{ secrets.APP_URL }}
          CRON_SECRET: ${{ secrets.CRON_SECRET }}
          KEYWORD: ${{ github.event.inputs.keyword || '„Åµ„Çã„Åï„Å®Á¥çÁ®é' }}
        run: |
          echo "üîç Scraping Google Trends for keyword: $KEYWORD"
          echo "üåê Target URL: ${APP_URL}/api/trends/scrape"
          echo "‚è∞ Timestamp: $(date -u +"%Y-%m-%d %H:%M:%S UTC")"

          # API„Ç®„É≥„Éâ„Éù„Ç§„É≥„Éà„ÇíÊßãÁØâ
          URL="${APP_URL}/api/trends/scrape?secret=${CRON_SECRET}&keyword=${KEYWORD}"

          # Áí∞Â¢ÉÂ§âÊï∞„ÉÅ„Çß„ÉÉ„ÇØ
          if [ -z "$APP_URL" ]; then
            echo "‚ùå ERROR: APP_URL is not set"
            exit 1
          fi
          if [ -z "$CRON_SECRET" ]; then
            echo "‚ùå ERROR: CRON_SECRET is not set"
            exit 1
          fi

          echo "üì° Calling API endpoint..."

          # API„ÇíÂëº„Å≥Âá∫„ÅóÔºàË©≥Á¥∞„É¢„Éº„Éâ„ÄÅ„Çø„Ç§„É†„Ç¢„Ç¶„Éà30ÁßíÔºâ
          RESPONSE=$(curl -s -w "\n%{http_code}\n%{time_total}\n%{size_download}" \
            --max-time 30 \
            --connect-timeout 10 \
            -X GET "$URL" 2>&1) || CURL_EXIT=$?

          # curlËá™‰Ωì„ÅÆ„Ç®„É©„Éº„ÉÅ„Çß„ÉÉ„ÇØ
          if [ ! -z "$CURL_EXIT" ]; then
            echo "‚ùå curl command failed with exit code: $CURL_EXIT"
            echo "Common curl exit codes:"
            echo "  6: Couldn't resolve host"
            echo "  7: Failed to connect to host"
            echo "  28: Operation timeout"
            echo "  35: SSL connect error"
            exit 1
          fi

          # „É¨„Çπ„Éù„É≥„ÇπËß£Êûê
          HTTP_CODE=$(echo "$RESPONSE" | tail -n3 | head -n1)
          TIME_TOTAL=$(echo "$RESPONSE" | tail -n2 | head -n1)
          SIZE_DOWNLOAD=$(echo "$RESPONSE" | tail -n1)
          BODY=$(echo "$RESPONSE" | sed '$d' | sed '$d' | sed '$d')

          echo "üìä Response Metrics:"
          echo "  - HTTP Status: $HTTP_CODE"
          echo "  - Response Time: ${TIME_TOTAL}s"
          echo "  - Response Size: ${SIZE_DOWNLOAD} bytes"
          echo ""
          echo "üìÑ Response Body:"
          echo "$BODY" | jq '.' 2>/dev/null || echo "$BODY"

          # HTTP„Çπ„ÉÜ„Éº„Çø„Çπ„Ç≥„Éº„Éâ„Çí„ÉÅ„Çß„ÉÉ„ÇØ
          if [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 300 ]; then
            echo ""
            echo "‚úÖ Successfully scraped Google Trends"
          else
            echo ""
            echo "‚ùå Failed to scrape Google Trends (HTTP $HTTP_CODE)"
            echo ""
            echo "üîç Debugging Information:"
            echo "  - Check if APP_URL is accessible: ${APP_URL}"
            echo "  - Verify CRON_SECRET is correct in GitHub Secrets"
            echo "  - Check Vercel deployment status"
            echo "  - Review API logs in Vercel dashboard"
            exit 1
          fi

      - name: Notify on failure
        if: failure()
        run: |
          echo "‚ùå Trends scraping job failed!"
          echo "Check the logs for more details."
